{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegreatgupta/ObjectRecognition/blob/master/Google_Colab_Notebook_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "9728f439-50c9-4f38-df9e-d291dd51a3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "outputId": "2de1f7f4-f4fb-4d92-9f21-e06542a836ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "10.063865595000038\n",
            "GPU (s):\n",
            "0.1937223529999983\n",
            "GPU speedup over CPU: 51x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sK7J71bGCpq7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Clone the Object Recognition Project from Github to fetch the Dataset and Start the training."
      ]
    },
    {
      "metadata": {
        "id": "O6HVukb0CogZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d6c6ce20-0411-4acb-ccc1-6050c957385f"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thegreatgupta/ObjectRecognition.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ObjectRecognition'...\n",
            "remote: Enumerating objects: 6879, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/6879)   \u001b[K\rremote: Counting objects:   1% (69/6879)   \u001b[K\rremote: Counting objects:   2% (138/6879)   \u001b[K\rremote: Counting objects:   3% (207/6879)   \u001b[K\rremote: Counting objects:   4% (276/6879)   \u001b[K\rremote: Counting objects:   5% (344/6879)   \u001b[K\rremote: Counting objects:   6% (413/6879)   \u001b[K\rremote: Counting objects:   7% (482/6879)   \u001b[K\rremote: Counting objects:   8% (551/6879)   \u001b[K\rremote: Counting objects:   9% (620/6879)   \u001b[K\rremote: Counting objects:  10% (688/6879)   \u001b[K\rremote: Counting objects:  11% (757/6879)   \u001b[K\rremote: Counting objects:  12% (826/6879)   \u001b[K\rremote: Counting objects:  13% (895/6879)   \u001b[K\rremote: Counting objects:  14% (964/6879)   \u001b[K\rremote: Counting objects:  15% (1032/6879)   \u001b[K\rremote: Counting objects:  16% (1101/6879)   \u001b[K\rremote: Counting objects:  17% (1170/6879)   \u001b[K\rremote: Counting objects:  18% (1239/6879)   \u001b[K\rremote: Counting objects:  19% (1308/6879)   \u001b[K\rremote: Counting objects:  20% (1376/6879)   \u001b[K\rremote: Counting objects:  21% (1445/6879)   \u001b[K\rremote: Counting objects:  22% (1514/6879)   \u001b[K\rremote: Counting objects:  23% (1583/6879)   \u001b[K\rremote: Counting objects:  24% (1651/6879)   \u001b[K\rremote: Counting objects:  25% (1720/6879)   \u001b[K\rremote: Counting objects:  26% (1789/6879)   \u001b[K\rremote: Counting objects:  27% (1858/6879)   \u001b[K\rremote: Counting objects:  28% (1927/6879)   \u001b[K\rremote: Counting objects:  29% (1995/6879)   \u001b[K\rremote: Counting objects:  30% (2064/6879)   \u001b[K\rremote: Counting objects:  31% (2133/6879)   \u001b[K\rremote: Counting objects:  32% (2202/6879)   \u001b[K\rremote: Counting objects:  33% (2271/6879)   \u001b[K\rremote: Counting objects:  34% (2339/6879)   \u001b[K\rremote: Counting objects:  35% (2408/6879)   \u001b[K\rremote: Counting objects:  36% (2477/6879)   \u001b[K\rremote: Counting objects:  37% (2546/6879)   \u001b[K\rremote: Counting objects:  38% (2615/6879)   \u001b[K\rremote: Counting objects:  39% (2683/6879)   \u001b[K\rremote: Counting objects:  40% (2752/6879)   \u001b[K\rremote: Counting objects:  41% (2821/6879)   \u001b[K\rremote: Counting objects:  42% (2890/6879)   \u001b[K\rremote: Counting objects:  43% (2958/6879)   \u001b[K\rremote: Counting objects:  44% (3027/6879)   \u001b[K\rremote: Counting objects:  45% (3096/6879)   \u001b[K\rremote: Counting objects:  46% (3165/6879)   \u001b[K\rremote: Counting objects:  47% (3234/6879)   \u001b[K\rremote: Counting objects:  48% (3302/6879)   \u001b[K\rremote: Counting objects:  49% (3371/6879)   \u001b[K\rremote: Counting objects:  50% (3440/6879)   \u001b[K\rremote: Counting objects:  51% (3509/6879)   \u001b[K\rremote: Counting objects:  52% (3578/6879)   \u001b[K\rremote: Counting objects:  53% (3646/6879)   \u001b[K\rremote: Counting objects:  54% (3715/6879)   \u001b[K\rremote: Counting objects:  55% (3784/6879)   \u001b[K\rremote: Counting objects:  56% (3853/6879)   \u001b[K\rremote: Counting objects:  57% (3922/6879)   \u001b[K\rremote: Counting objects:  58% (3990/6879)   \u001b[K\rremote: Counting objects:  59% (4059/6879)   \u001b[K\rremote: Counting objects:  60% (4128/6879)   \u001b[K\rremote: Counting objects:  61% (4197/6879)   \u001b[K\rremote: Counting objects:  62% (4265/6879)   \u001b[K\rremote: Counting objects:  63% (4334/6879)   \u001b[K\rremote: Counting objects:  64% (4403/6879)   \u001b[K\rremote: Counting objects:  65% (4472/6879)   \u001b[K\rremote: Counting objects:  66% (4541/6879)   \u001b[K\rremote: Counting objects:  67% (4609/6879)   \u001b[K\rremote: Counting objects:  68% (4678/6879)   \u001b[K\rremote: Counting objects:  69% (4747/6879)   \u001b[K\rremote: Counting objects:  70% (4816/6879)   \u001b[K\rremote: Counting objects:  71% (4885/6879)   \u001b[K\rremote: Counting objects:  72% (4953/6879)   \u001b[K\rremote: Counting objects:  73% (5022/6879)   \u001b[K\rremote: Counting objects:  74% (5091/6879)   \u001b[K\rremote: Counting objects:  75% (5160/6879)   \u001b[K\rremote: Counting objects:  76% (5229/6879)   \u001b[K\rremote: Counting objects:  77% (5297/6879)   \u001b[K\rremote: Counting objects:  78% (5366/6879)   \u001b[K\rremote: Counting objects:  79% (5435/6879)   \u001b[K\rremote: Counting objects:  80% (5504/6879)   \u001b[K\rremote: Counting objects:  81% (5572/6879)   \u001b[K\rremote: Counting objects:  82% (5641/6879)   \u001b[K\rremote: Counting objects:  83% (5710/6879)   \u001b[K\rremote: Counting objects:  84% (5779/6879)   \u001b[K\rremote: Counting objects:  85% (5848/6879)   \u001b[K\rremote: Counting objects:  86% (5916/6879)   \u001b[K\rremote: Counting objects:  87% (5985/6879)   \u001b[K\rremote: Counting objects:  88% (6054/6879)   \u001b[K\rremote: Counting objects:  89% (6123/6879)   \u001b[K\rremote: Counting objects:  90% (6192/6879)   \u001b[K\rremote: Counting objects:  91% (6260/6879)   \u001b[K\rremote: Counting objects:  92% (6329/6879)   \u001b[K\rremote: Counting objects:  93% (6398/6879)   \u001b[K\rremote: Counting objects:  94% (6467/6879)   \u001b[K\rremote: Counting objects:  95% (6536/6879)   \u001b[K\rremote: Counting objects:  96% (6604/6879)   \u001b[K\rremote: Counting objects:  97% (6673/6879)   \u001b[K\rremote: Counting objects:  98% (6742/6879)   \u001b[K\rremote: Counting objects:  99% (6811/6879)   \u001b[K\rremote: Counting objects: 100% (6879/6879)   \u001b[K\rremote: Counting objects: 100% (6879/6879), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6866/6866), done.\u001b[K\n",
            "remote: Total 6879 (delta 36), reused 6838 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (6879/6879), 123.69 MiB | 31.35 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "Checking out files: 100% (6951/6951), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jp_Ml9ydDUKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc6fe67e-4c69-45b7-df86-b91e26954e96"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ObjectRecognition  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zMnSKufsDc4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0628b139-2e10-4392-e4ab-64d83bba2c71"
      },
      "cell_type": "code",
      "source": [
        "cd ObjectRecognition"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ObjectRecognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-649s4uDr7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ec008934-3a90-4bd8-d1cd-0dfe2e0835b7"
      },
      "cell_type": "code",
      "source": [
        "!ls dataset/training_set_test/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airplanes\t   crab\t\t    Faces_easy\t lamp\t     scorpion\n",
            "BACKGROUND_Google  crayfish\t    ferry\t laptop      soccer_ball\n",
            "bonsai\t\t   dalmatian\t    flamingo\t Leopards    starfish\n",
            "brain\t\t   dolphin\t    grand_piano  llama\t     stop_sign\n",
            "buddha\t\t   dragonfly\t    hawksbill\t lotus\t     sunflower\n",
            "butterfly\t   electric_guitar  helicopter\t menorah     trilobite\n",
            "car_side\t   elephant\t    ibis\t minaret     umbrella\n",
            "chair\t\t   euphonium\t    joshua_tree  Motorbikes  watch\n",
            "chandelier\t   ewer\t\t    kangaroo\t revolver    yin_yang\n",
            "cougar_face\t   Faces\t    ketch\t schooner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qMAT4-3XEnt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Start Training the Model Using GPU"
      ]
    },
    {
      "metadata": {
        "id": "fLe8QPwIE_ec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import Packages to the Notebook"
      ]
    },
    {
      "metadata": {
        "id": "vd1CT_T2Ee4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b05d30ec-6dc0-46ca-e3ad-2297210e6a32"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.applications.xception import Xception\n",
        "#from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cXj3DnMWFK37",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Declare Instance Variables "
      ]
    },
    {
      "metadata": {
        "id": "yWYS5NOYFHHw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_set = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kP0NjzjDFWxN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create Model Method"
      ]
    },
    {
      "metadata": {
        "id": "BQHwhi5tFRPo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(img_shape=(299, 299, 3), n_classes=50,\n",
        "                   load_pretrained=False, freeze_layers_from='base_model'):\n",
        "    # Decide if load pretrained weights from imagenet\n",
        "    if load_pretrained:\n",
        "        weights = 'imagenet'\n",
        "    else:\n",
        "        weights = None\n",
        "\n",
        "    # Get base model\n",
        "    #base_model = Xception(include_top=False, weights=weights,\n",
        "                       #input_tensor=None, input_shape=img_shape)\n",
        "    \n",
        "    #base_model = ResNet50(include_top=False, weights=weights,\n",
        "                       #input_tensor=None, input_shape=img_shape)\n",
        "    \n",
        "    base_model = MobileNet(include_top=False, weights=weights,\n",
        "                       input_tensor=None, input_shape=img_shape)\n",
        "\n",
        "    # Add final layers\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(n_classes, activation='relu')(x)\n",
        "    predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    # This is the model we will train\n",
        "    model = Model(input=base_model.input, output=predictions)\n",
        "    \n",
        "    # Model Summary\n",
        "    # print(model.summary())\n",
        "    \n",
        "    # Freeze some layers\n",
        "    if freeze_layers_from is not None:\n",
        "        if freeze_layers_from == 'base_model':\n",
        "            print ('   Freezing base model layers')\n",
        "            for layer in base_model.layers:\n",
        "                layer.trainable = False\n",
        "        else:\n",
        "            for i, layer in enumerate(model.layers):\n",
        "                print(i, layer.name)\n",
        "            print ('   Freezing from layer 0 to ' + str(freeze_layers_from))\n",
        "            for layer in model.layers[:freeze_layers_from]:\n",
        "               layer.trainable = False\n",
        "            for layer in model.layers[freeze_layers_from:]:\n",
        "               layer.trainable = True\n",
        "\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIRlQZJgFsw4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "tZZPP0ksFpQg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(train_set_path, val_set_path, validation_split = 0.2,\n",
        "                   batch_size = 32, class_mode = 'categorical', horizontal_flip = False,\n",
        "                   vertical_flip = False, rotation_range = None, target_size = (299, 299),\n",
        "                   model = None, epochs = 1, learning_rate = 0.0001, loss = 'categorical_crossentropy',\n",
        "\t\t\t\t   n_classes=50):\n",
        "    \n",
        "    # Load Image Data Set Using Keras\n",
        "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = horizontal_flip,\n",
        "                                   vertical_flip = vertical_flip,\n",
        "                                   rotation_range=rotation_range,\n",
        "                                   validation_split=validation_split)\n",
        "    \n",
        "    training_set = train_datagen.flow_from_directory(train_set_path,\n",
        "                                                 target_size = target_size,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = class_mode,\n",
        "                                                 subset = 'training')\n",
        "    \n",
        "    validation_set = train_datagen.flow_from_directory(val_set_path,\n",
        "                                                 target_size = target_size,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = class_mode,\n",
        "                                                 subset = 'validation')\n",
        "        \n",
        "    # Compile Model\n",
        "    # opt_rms = keras.optimizers.rmsprop(lr=learning_rate,decay=1e-6)\n",
        "    adam_optimizer = Adam(lr = learning_rate)\n",
        "    model.compile(optimizer = adam_optimizer, loss = loss, metrics = ['accuracy'])\n",
        "    \n",
        "    model.fit_generator(training_set,\n",
        "                        steps_per_epoch = training_set.samples,\n",
        "                        epochs = epochs,\n",
        "                        validation_data = validation_set,\n",
        "                        validation_steps = validation_set.samples)\n",
        "        \n",
        "    model.evaluate_generator(training_set, n_classes)\n",
        "    model.evaluate_generator(validation_set, n_classes)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "le4sxYOOGP4N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model Initialization Method to Create and Train the Model on the dataset"
      ]
    },
    {
      "metadata": {
        "id": "9WQ26RoFFxMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_initialization():\n",
        "\t# Declare Constants\n",
        "\timg_shape = (128, 128, 3)\n",
        "\ttarget_size = (128, 128)\n",
        "\tn_classes = 49\n",
        "\tepochs = 1\n",
        "\ttrain_set_path = 'dataset/training_set_test' #'101_ObjectCategories'\n",
        "\tval_set_path = train_set_path\n",
        "\tvalidation_split = 0.50\n",
        "\tbatch_size = 1\n",
        "\thorizontal_flip = True\n",
        "\trotation_range = None\n",
        "\tlearning_rate = 0.0003\n",
        "\tloss = 'categorical_crossentropy'\n",
        "\n",
        "\t# Build Model\n",
        "\tmodel = create_model(img_shape = img_shape,  n_classes = n_classes, load_pretrained = True)\n",
        "\n",
        "    #model = load_model('mobilenet_ooo3_015_10_16_model_2')\n",
        "\t#model.load_weights('mobilenet_ooo3_015_10_16_2.h5')\n",
        "\n",
        "\t# Train the Model\n",
        "\tmodel = train_model(train_set_path = train_set_path, val_set_path = val_set_path, validation_split = validation_split,\n",
        "\t\t\t\t\t\t   batch_size = batch_size, horizontal_flip = horizontal_flip, rotation_range = rotation_range,\n",
        "\t\t\t\t\t\t   model = model, epochs = epochs, target_size = target_size, learning_rate = learning_rate,\n",
        "                           loss = loss, n_classes = n_classes)\n",
        "\n",
        "\tmodel.save_weights('saved_model/20190317/weight_01.h5')\n",
        "\tmodel.save('saved_model/20190317/model_01')\n",
        "\tjson_string = model.to_json()\n",
        "\tf = open('saved_model/20190317/json_model_01.json', 'w+')\n",
        "\tf.write(json_string)\n",
        "\tf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwZyRKBqGh_O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Call Model Initialization Method to start"
      ]
    },
    {
      "metadata": {
        "id": "m4fauFt8Gclo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_initialization()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}